import { Code } from 'components/om/Code';
import { CodeTabs } from 'components/om/CodeTabs';

# Основы составления промтов

## Простые промты

С помощью элементарных промтов можно решить множество задач, но качество результата будет зависеть от объема информации в промте и от того, насколько хорошо она подготовлена (а еще от исходных характеристик БЯМ). Промт может включать в себя _инструкцию_ или _вопрос_, а также другую информацию, такую как _контекст_, _входные данные_ и _примеры_. Эти компоненты позволяют усовершенствовать запрос к модели и, как следствие, улучшить результат.

Начнем с простого промта:

<Code filename="Промт">{"Погода сегодня"}</Code>

export function Results0() {
    const list = [
        {tab: 'Llama 2 13B', name: 'Результат', code:", 17 декабря\n\n* Скорость ветра: 0,6 м/с, направление: 295°, давление: 748 мм ртутного столба.\n"},
        {tab: 'ruGPT-3.5 13B', name: 'Результат', code:"в Краснодаре облачная, днем +8..+10 градусов тепла. \n\nСильный ветер ожидается утром и вечером 12 февраля."},
        {tab: 'ChatGPT 3.5', name: 'Результат', code:"Извините, но я не могу предоставить актуальную информацию о погоде, так как моя база данных обновлена в январе 2022 года, и у меня нет доступа к интернету для получения текущей информации о погоде. Чтобы узнать текущую погоду, вы можете воспользоваться местными метеорологическими ресурсами, приложениями для смартфонов или посетить веб-сайты, предоставляющие информацию о погоде."},
        {tab: 'ChatGPT 4', name: 'Результат', code:"The weather in Moscow today features temperatures ranging from +8°C to +10°C (46°F to 50°F). The wind is blowing from the south at a speed of 1 to 2 meters per second (4 to 7 km/h) and will later shift to come from the west. There is a likelihood of light precipitation, varying from 0 to 1.7 mm throughout the day. Atmospheric pressure is expected to range between 735 to 742 mmHg (980 to 989 hPa), and relative humidity will fluctuate between 81% to 93%."},
        {tab: 'GigaChat', name: 'Результат', code:"К сожалению, я не могу предоставить актуальную информацию о погоде, так как я не имею доступа к интернету и не могу получать данные с метеорологических сайтов. Однако, если у вас есть конкретный вопрос о погоде, я постараюсь помочь вам ответить на него."},
    ]
    return <CodeTabs list={list} />;
}

<Results0 />

Llama 2 и ruGPT-3.5 сгенерировали последовательность, имеющую смысл в контексте «Погода сегодня».

ChatGPT 3.5 и GigaChat восприняли промт как желание узнать текущую информацию о погоде, но выполнить запрос не смогли. ChatGPT 4 воспользовался поисковиком и выдал информацию о погоде, но на английском языке. Итак, в общем случае результат генерации в ответ на такой абстрактный запрос может быть абсолютно неожиданным или далеким от задачи, которую нужно выполнить.

Этот простой пример показывает, что необходимо предоставлять более подробный контекст или инструкции, объясняющие, что именно надо сделать.

Попробуем немного доработать промт:

<Code filename="Промт">{"Закончи фразу:\n\nПогода сегодня"}</Code>

export function Results1() {
    const list = [
        {tab: 'Llama 2 13B', name: 'Результат', code: "не отличается от прошлой."},
        {tab: 'ruGPT-3.5 13B', name: 'Результат', code: "хорошая, но холодно.\n\n< ... >"},
        {tab: 'ChatGPT 3.5', name: 'Результат', code: "Погода сегодня зависит от вашего местоположения и времени года."},
        {tab: 'ChatGPT 4', name: 'Результат', code: "отличная для прогулки на свежем воздухе."},
        {tab: 'GigaChat', name: 'Результат', code: "просто замечательная! Солнце светит ярко, небо голубое и без единого облачка."},
    ]
    return <CodeTabs list={list} />;
}

<Results1 />

Улучшился ли результат? В каком-то смысле да. Мы попросили завершить фразу, Llama 2 и ChatGPT 4 сделали именно это; ruGPT-3.5 и GigaChat тоже завершили фразу, а затем начали новое предложение; ChatGPT 3.5 повторил в ответе начало фразы — и генерировал результат в том же виде даже после нескольких попыток скорректировать промт. Такая деятельность по составлению оптимальных запросов, объясняющих модели задачу, и называется **разработкой промтов**.

Рассмотренный пример — лишь базовая демонстрация возможностей современных БЯМ. Сегодня большие языковые модели способны выполнять различные виды сложных заданий, от автоматического реферирования текста до решения математических задач и генерации программного кода.

## Форматирование промта

Промт, который мы использовали для первого примера, был очень простым. Стандартный промт имеет следующий вид:

```
<Вопрос>?
```

или

```
<Инструкция>
```

Можно создать промт в вопросно-ответной форме (ВО). Такое оформление является стандартным для многих обучающих наборов данных, и многие модели его «понимают»:

```
В: <Вопрос>?
О:
```

Вопросно-ответная форма вариативна и зависит от набора данных, на котором обучалась модель. Некоторые модели требуют другого оформления:

```
Вопрос: <Вопрос>?
Ответ:
```

Промт такого типа называется _запросом без примера_ (zero-shot prompting), то есть у модели сразу запрашивается ответ без приведения каких-либо образцов выполнения задания. Некоторые большие языковые модели успешно справляются с такими запросами, но результат зависит от сложности поставленной задачи и ее понимания моделью.

Если промт, описанный выше, дополнить образцами выполнения задачи, получится «_запрос с несколькими примерами_» (few-shot prompting) — это одна из популярных и эффективных техник. Промт с несколькими примерами выглядит так:

```
<Вопрос>?
<Ответ>

<Вопрос>?
<Ответ>

<Вопрос>?
<Ответ>

<Вопрос>?
```

Версия в форме ВО выглядела бы так:

```
В: <Вопрос>?
О: <Ответ>

В: <Вопрос>?
О: <Ответ>

В: <Вопрос>?
О: <Ответ>

В: <Вопрос>?
О:
```

Использовать именно вопросно-ответную форму необязательно. Оформление промта зависит от конкретной задачи. Например, для простой задачи классификации промт с несколькими примерами может выглядеть так:

<Code filename="Промт">{"Восторг! // Позитивный\nНеудачный фильм // Негативный\nКлассное кино! // Позитивный\nБольшое разочарование! //"}</Code>

export function Results2() {
    const list = [
        {tab: 'Llama 2 13B', name: 'Результат', code: "Негативный"},
        {tab: 'ruGPT-3.5 13B', name: 'Результат', code: "Негативный\n\n< ... >"},
        {tab: 'ChatGPT 3.5', name: 'Результат', code: "Негативный"},
        {tab: 'ChatGPT 4', name: 'Результат', code: "These phrases express different sentiments about a film. Here's what they convey:\n\n\"Восторг!\" (Delight!) - Positive\n\"Неудачный фильм\" (Unsuccessful movie) - Negative\n\"Классное кино!\" (Cool movie!) - Positive\n\"Большое разочарование!\" (Big disappointment!) - Negative\n\nThese could be reviews or reactions one might have after watching a movie."},
        {tab: 'GigaChat', name: 'Результат', code: "Негативный"},
    ]
    return <CodeTabs list={list} />;
}

<Results2 />

Результат, полностью соответствующий ожиданиям, выдали только ChatGPT 3.5 и GigaChat. Llama 2 и ruGPT-3.5 ответили правильно, но затем продолжили генерацию. ChatGPT 4 правильно определил тональность текста, однако сделал это на английском языке, добавив перевод и пояснения. Кроме того, при цитировании и переводе он изменил формат запроса.

Запросы с несколькими примерами позволяют обучить модель в рамках текущего контекста. Это работает благодаря способности языковых моделей осваивать решение задач, для которых приведено несколько образцов результата. Необходимо отметить, что новые умения сохраняются только в пределах длины контекста модели.
